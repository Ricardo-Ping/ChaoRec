"""
-*- coding: utf-8 -*-

@Author : Ricardo_PING
@Time : 2024/9/6 10:54
@File : DiffMM.py
@function :
"""
import torch
from scipy.sparse import coo_matrix
from torch import nn
import torch.nn.functional as F
import numpy as np
import random
import math
import scipy.sparse as sp


class GCNLayer(nn.Module):
    def __init__(self):
        super(GCNLayer, self).__init__()

    def forward(self, adj, embeds):
        return torch.spmm(adj, embeds)


class SpAdjDropEdge(nn.Module):
    def __init__(self, keepRate):
        super(SpAdjDropEdge, self).__init__()
        self.keepRate = keepRate

    def forward(self, adj):
        vals = adj._values()
        idxs = adj._indices()
        edgeNum = vals.size()
        mask = ((torch.rand(edgeNum) + self.keepRate).floor()).type(torch.bool)

        newVals = vals[mask] / self.keepRate
        newIdxs = idxs[:, mask]

        return torch.sparse.FloatTensor(newIdxs, newVals, adj.shape)


class DiffMM(nn.Module):
    def __init__(self, num_user, num_item, edge_index, user_item_dict, v_feat, t_feat, dim_E,
                 reg_weight, n_layers, ssl_alpha, ssl_temp, ris_lambda, e_loss, rebuild_k, device):
        super(DiffMM, self).__init__()
        self.restore_itmEmbeds = None
        self.restore_usrEmbeds = None
        self.num_user = num_user
        self.num_item = num_item
        self.edge_index = edge_index
        self.user_item_dict = user_item_dict
        self.dim_E = dim_E
        self.reg_weight = reg_weight
        self.device = device
        self.ris_adj_lambda = 0.2
        self.ris_lambda = ris_lambda  # eq23ä¸­çš„ğœ”
        self.steps = 5
        self.noise_scale = 0.1
        self.noise_min = 0.0001
        self.noise_max = 0.02
        self.trans = 1
        self.ssl_temp = ssl_temp  # æ¸©åº¦ç³»æ•°
        self.ssl_alpha = ssl_alpha
        self.cl_method = 0  # 0:m vs m ; 1:m vs main
        self.n_layers = n_layers
        self.e_loss = e_loss
        self.rebuild_k = rebuild_k

        # åˆå§‹åŒ–ç”¨æˆ·å’Œé¡¹ç›®åµŒå…¥
        self.uEmbeds = nn.Parameter(nn.init.xavier_uniform_(torch.empty(num_user, dim_E)))
        self.iEmbeds = nn.Parameter(nn.init.xavier_uniform_(torch.empty(num_item, dim_E)))
        # å¤šå±‚ GCN å›¾å·ç§¯å±‚
        self.gcnLayers = nn.Sequential(*[GCNLayer() for i in range(n_layers)])

        adjusted_item_ids = edge_index[:, 1] - self.num_user
        # åˆ›å»ºCOOæ ¼å¼çš„ç¨€ç–çŸ©é˜µ
        self.interaction_matrix = sp.coo_matrix((np.ones(len(edge_index)),  # å¡«å……1è¡¨ç¤ºå­˜åœ¨äº¤äº’
                                                 (edge_index[:, 0], adjusted_item_ids)),  # ç”¨æˆ·IDå’Œè°ƒæ•´åçš„é¡¹ç›®ID
                                                shape=(self.num_user, self.num_item), dtype=np.float32)
        self.adj = self.get_norm_adj_mat().to(self.device)

        # ç¨€ç–å›¾è¾¹çš„éšæœºä¸¢å¼ƒï¼Œç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆ
        keepRate = 0.5
        self.edgeDropper = SpAdjDropEdge(keepRate)

        # æ ¹æ®trans çš„å€¼ï¼Œåˆå§‹åŒ–ä¸åŒçš„å¤šæ¨¡æ€ç‰¹å¾å˜æ¢æ–¹å¼
        if self.trans == 1:
            self.image_trans_l = nn.Linear(v_feat.shape[1], self.dim_E)
            self.text_trans_l = nn.Linear(t_feat.shape[1], self.dim_E)
            nn.init.xavier_uniform_(self.image_trans_l.weight)
            nn.init.xavier_uniform_(self.text_trans_l.weight)
        elif self.trans == 0:
            self.image_trans = nn.Parameter(nn.init.xavier_uniform_(torch.empty(size=(v_feat.shape[1], dim_E))))
            self.text_trans = nn.Parameter(nn.init.xavier_uniform_(torch.empty(size=(t_feat.shape[1], dim_E))))

        self.image_embedding = v_feat
        self.text_embedding = t_feat
        self.modal_weight = nn.Parameter(torch.Tensor([0.5, 0.5]))  # ä¸¤ä¸ªæ¨¡æ€çš„æƒé‡å‡åˆ†

        self.softmax = nn.Softmax(dim=0)
        self.dropout = nn.Dropout(p=0.1)
        self.leakyrelu = nn.LeakyReLU(0.2)

        dims = '[1000]'
        out_dims = eval(dims) + [num_item]  # [1000, num_item]
        in_dims = out_dims[::-1]  # [num_item, 1000]
        norm = False
        d_emb_size = 10
        self.denoise_model_image = Denoise(in_dims, out_dims, d_emb_size, norm=norm).to(self.device)
        self.denoise_model_text = Denoise(in_dims, out_dims, d_emb_size, norm=norm).to(self.device)

        self.diffusion_model = GaussianDiffusion(self.noise_scale, self.noise_min, self.noise_max, self.steps).to(self.device)

    def get_norm_adj_mat(self):
        # åˆ›å»ºä¸€ä¸ªç©ºçš„ç¨€ç–çŸ©é˜µAï¼Œå¤§å°ä¸º(n_users+n_items) x (n_users+n_items)ï¼Œæ•°æ®ç±»å‹ä¸ºfloat32
        A = sp.dok_matrix((self.num_user + self.num_item, self.num_user + self.num_item), dtype=np.float32)
        # åŠ è½½äº¤äº’çŸ©é˜µ
        inter_M = self.interaction_matrix
        # å°†äº¤äº’çŸ©é˜µè½¬ç½®ï¼Œä»¥ä¾¿è·å–ç‰©å“åˆ°ç”¨æˆ·çš„å…³ç³»
        inter_M_t = self.interaction_matrix.transpose()
        # å°†ç”¨æˆ·åˆ°ç‰©å“çš„äº¤äº’å’Œç‰©å“åˆ°ç”¨æˆ·çš„äº¤äº’åˆå¹¶åˆ°é‚»æ¥çŸ©é˜µAä¸­
        # æ³¨æ„ï¼šç‰©å“çš„ç´¢å¼•éœ€è¦åŠ ä¸Šç”¨æˆ·çš„æ•°é‡ï¼Œå› ä¸ºçŸ©é˜µçš„å‰åŠéƒ¨åˆ†æ˜¯ç”¨æˆ·ï¼ŒååŠéƒ¨åˆ†æ˜¯ç‰©å“
        # nnz å±æ€§è¡¨ç¤ºç¨€ç–çŸ©é˜µä¸­çš„éé›¶å…ƒç´ çš„æ•°é‡
        data_dict = dict(zip(zip(inter_M.row, inter_M.col + self.num_user), [1] * inter_M.nnz))
        data_dict.update(dict(zip(zip(inter_M_t.row + self.num_user, inter_M_t.col), [1] * inter_M_t.nnz)))
        # æ›´æ–°ç¨€ç–çŸ©é˜µAçš„æ•°æ®
        A._update(data_dict)

        # å½’ä¸€åŒ–é‚»æ¥çŸ©é˜µ
        # è®¡ç®—Aä¸­æ¯ä¸ªèŠ‚ç‚¹çš„åº¦ï¼ˆå³æ¯è¡Œçš„éé›¶å…ƒç´ ä¸ªæ•°ï¼‰
        sumArr = (A > 0).sum(axis=1)
        # ä¸ºäº†é˜²æ­¢é™¤ä»¥0ï¼Œç»™åº¦æ•°åŠ ä¸Šä¸€ä¸ªå¾ˆå°çš„æ•°epsilon
        diag = np.array(sumArr.flatten())[0] + 1e-7
        # åº¦æ•°çš„-0.5æ¬¡å¹‚ï¼Œç”¨äºæ‹‰æ™®æ‹‰æ–¯çŸ©é˜µçš„å½’ä¸€åŒ–
        diag = np.power(diag, -0.5)
        # å°†numpyæ•°ç»„è½¬æ¢ä¸ºtorchå¼ é‡ï¼Œå¹¶ç§»åŠ¨åˆ°æ¨¡å‹çš„è®¾å¤‡ä¸Šï¼ˆCPUæˆ–GPUï¼‰
        self.diag = torch.from_numpy(diag).to(self.device)
        # åˆ›å»ºå¯¹è§’çŸ©é˜µD
        D = sp.diags(diag)
        # ä½¿ç”¨Då¯¹Aè¿›è¡Œå½’ä¸€åŒ–ï¼šL = D^-0.5 * A * D^-0.5
        L = D @ A @ D
        # å°†å½’ä¸€åŒ–åçš„Lè½¬æ¢ä¸ºCOOæ ¼å¼çš„ç¨€ç–çŸ©é˜µï¼Œä»¥ä¾¿åç»­è½¬æ¢ä¸ºtorchç¨€ç–å¼ é‡
        L = sp.coo_matrix(L)
        row = L.row
        col = L.col
        # åˆ›å»ºtorchå¼ é‡æ¥è¡¨ç¤ºç¨€ç–çŸ©é˜µçš„åæ ‡(indices)å’Œå€¼(values)
        rows_and_cols = np.array([row, col])  # å°†è¡Œå’Œåˆ—çš„åˆ—è¡¨è½¬æ¢æˆnumpyæ•°ç»„
        i = torch.tensor(rows_and_cols, dtype=torch.long)  # ä»numpyæ•°ç»„åˆ›å»ºå¼ é‡
        data = torch.FloatTensor(L.data)
        # åˆ›å»ºtorchçš„ç¨€ç–å¼ é‡æ¥è¡¨ç¤ºå½’ä¸€åŒ–çš„é‚»æ¥çŸ©é˜µ
        # SparseL = torch.sparse.FloatTensor(i, data, torch.Size(L.shape))
        SparseL = torch.sparse_coo_tensor(i, data, torch.Size(L.shape), dtype=torch.float32)

        return SparseL

    # åˆ›å»ºæ¨¡æ€é‚»æ¥çŸ©é˜µ
    def normalizeAdj(self, mat):
        degree = np.array(mat.sum(axis=-1))
        dInvSqrt = np.reshape(np.power(degree, -0.5), [-1])
        dInvSqrt[np.isinf(dInvSqrt)] = 0.0
        dInvSqrtMat = sp.diags(dInvSqrt)
        return mat.dot(dInvSqrtMat).transpose().dot(dInvSqrtMat).tocoo()

    def buildUIMatrix(self, u_list, i_list, edge_list):
        mat = coo_matrix((edge_list, (u_list, i_list)), shape=(self.num_user, self.num_item), dtype=np.float32)

        a = sp.csr_matrix((self.num_user, self.num_user))
        b = sp.csr_matrix((self.num_item, self.num_item))
        mat = sp.vstack([sp.hstack([a, mat]), sp.hstack([mat.transpose(), b])])
        mat = (mat != 0) * 1.0
        mat = (mat + sp.eye(mat.shape[0])) * 1.0
        mat = self.normalizeAdj(mat)

        idxs = torch.from_numpy(np.vstack([mat.row, mat.col]).astype(np.int64))
        vals = torch.from_numpy(mat.data.astype(np.float32))
        shape = torch.Size(mat.shape)

        return torch.sparse.FloatTensor(idxs, vals, shape).cuda()

    def getItemEmbeds(self):
        return self.iEmbeds

    def getUserEmbeds(self):
        return self.uEmbeds

    def getImageFeats(self):
        if self.trans == 0:
            image_feats = self.leakyrelu(torch.mm(self.image_embedding, self.image_trans))
            return image_feats
        elif self.trans == 1:
            image_feats = self.image_trans_l(self.image_embedding)
            return image_feats

    def getTextFeats(self):
        if self.trans == 0:
            text_feats = self.leakyrelu(torch.mm(self.text_embedding, self.text_trans))
            return text_feats
        elif self.trans == 1:
            text_feats = self.text_trans_l(self.text_embedding)
            return text_feats

    def forward_MM(self, image_adj, text_adj):
        # å¦‚æœ args.trans == 0ï¼ˆä¸ä½¿ç”¨çº¿æ€§å±‚è¿›è¡Œè½¬æ¢ï¼‰ï¼Œåˆ™ä½¿ç”¨ leakyrelu æ¿€æ´»å‡½æ•°å¯¹å›¾åƒå’Œæ–‡æœ¬ç‰¹å¾è¿›è¡Œå˜æ¢
        if self.trans == 0:
            image_feats = self.leakyrelu(torch.mm(self.image_embedding, self.image_trans))  # å›¾åƒç‰¹å¾é€šè¿‡çŸ©é˜µä¹˜æ³•è¿›è¡Œå˜æ¢
            text_feats = self.leakyrelu(torch.mm(self.text_embedding, self.text_trans))  # æ–‡æœ¬ç‰¹å¾é€šè¿‡çŸ©é˜µä¹˜æ³•è¿›è¡Œå˜æ¢
        # å¦‚æœ args.trans == 1ï¼Œä½¿ç”¨çº¿æ€§å±‚è¿›è¡Œç‰¹å¾å˜æ¢
        elif self.trans == 1:
            image_feats = self.image_trans_l(self.image_embedding)  # é€šè¿‡çº¿æ€§å±‚å˜æ¢å›¾åƒç‰¹å¾
            text_feats = self.text_trans_l(self.text_embedding)  # é€šè¿‡çº¿æ€§å±‚å˜æ¢æ–‡æœ¬ç‰¹å¾

        # é€šè¿‡ softmax å¯¹æ¨¡æ€æƒé‡è¿›è¡Œå½’ä¸€åŒ–
        weight = self.softmax(self.modal_weight)

        # è§†è§‰é‚»æ¥çŸ©é˜µå¤„ç†ï¼šæ‹¼æ¥ç”¨æˆ·å’Œé¡¹ç›®åµŒå…¥ï¼Œè¿›è¡Œå›¾å·ç§¯
        embedsImageAdj = torch.concat([self.uEmbeds, self.iEmbeds])
        embedsImageAdj = torch.spmm(image_adj, embedsImageAdj)

        # å¤„ç†å›¾åƒç‰¹å¾ï¼šæ‹¼æ¥ç”¨æˆ·åµŒå…¥å’Œæ ‡å‡†åŒ–åçš„å›¾åƒç‰¹å¾ï¼Œå¹¶è¿›è¡Œå›¾å·ç§¯
        embedsImage = torch.concat([self.uEmbeds, F.normalize(image_feats)])
        embedsImage = torch.spmm(self.adj, embedsImage)

        # å†æ¬¡æ›´æ–°å›¾åƒç‰¹å¾ï¼Œä½¿ç”¨ä»ç”¨æˆ·åµŒå…¥å’Œé¡¹ç›®åµŒå…¥çš„ç»„åˆè¿›è¡Œå›¾å·ç§¯
        embedsImage_ = torch.concat([embedsImage[:self.num_user], self.iEmbeds])
        embedsImage_ = torch.spmm(self.adj, embedsImage_)
        embedsImage += embedsImage_  # eq20

        # æ–‡æœ¬é‚»æ¥çŸ©é˜µå¤„ç†ï¼šæ‹¼æ¥ç”¨æˆ·å’Œé¡¹ç›®åµŒå…¥ï¼Œè¿›è¡Œå›¾å·ç§¯
        embedsTextAdj = torch.concat([self.uEmbeds, self.iEmbeds])
        embedsTextAdj = torch.spmm(text_adj, embedsTextAdj)

        # å¤„ç†æ–‡æœ¬ç‰¹å¾ï¼šæ‹¼æ¥ç”¨æˆ·åµŒå…¥å’Œæ ‡å‡†åŒ–åçš„æ–‡æœ¬ç‰¹å¾ï¼Œå¹¶è¿›è¡Œå›¾å·ç§¯
        embedsText = torch.concat([self.uEmbeds, F.normalize(text_feats)])
        embedsText = torch.spmm(self.adj, embedsText)

        # å†æ¬¡æ›´æ–°æ–‡æœ¬ç‰¹å¾ï¼Œä½¿ç”¨ä»ç”¨æˆ·åµŒå…¥å’Œé¡¹ç›®åµŒå…¥çš„ç»„åˆè¿›è¡Œå›¾å·ç§¯
        embedsText_ = torch.concat([embedsText[:self.num_user], self.iEmbeds])
        embedsText_ = torch.spmm(self.adj, embedsText_)
        embedsText += embedsText_

        # åŠ å…¥ RISï¼ˆResidual Information Smoothingï¼‰æ­£åˆ™åŒ–é¡¹ï¼Œå¯¹å›¾åƒã€æ–‡æœ¬çš„ç‰¹å¾è¿›è¡Œé¢å¤–çš„é‚»æ¥çŸ©é˜µå¤„ç† eq21
        embedsImage += self.ris_adj_lambda * embedsImageAdj
        embedsText += self.ris_adj_lambda * embedsTextAdj

        # åŠ æƒå¤šæ¨¡æ€ç‰¹å¾çš„èåˆ  eq21
        embedsModal = weight[0] * embedsImage + weight[1] * embedsText

        # å°†å¤šæ¨¡æ€èåˆåçš„åµŒå…¥è¾“å…¥åˆ° GCN å±‚ä¸­ï¼Œè¿›è¡Œå¤šå±‚å›¾å·ç§¯  eq22
        embeds = embedsModal
        embedsLst = [embeds]  # ä¿å­˜æ¯ä¸€å±‚çš„åµŒå…¥
        for gcn in self.gcnLayers:
            embeds = gcn(self.adj, embedsLst[-1])
            embedsLst.append(embeds)
        embeds = sum(embedsLst)  # å°†æ¯ä¸€å±‚çš„åµŒå…¥ç»“æœç›¸åŠ 

        # åŠ å…¥ RIS æ­£åˆ™åŒ–é¡¹ï¼Œå¯¹æœ€ç»ˆçš„åµŒå…¥ç»“æœè¿›è¡Œå½’ä¸€åŒ–å¤„ç† eq23
        embeds = embeds + self.ris_lambda * F.normalize(embedsModal)

        # è¿”å›ç”¨æˆ·åµŒå…¥å’Œé¡¹ç›®åµŒå…¥
        return embeds[:self.num_user], embeds[self.num_user:]

    def forward_cl_MM(self, image_adj, text_adj):
        if self.trans == 0:
            # ä½¿ç”¨ leakyrelu æ¿€æ´»å‡½æ•°å’ŒçŸ©é˜µä¹˜æ³•è½¬æ¢å›¾åƒå’Œæ–‡æœ¬ç‰¹å¾
            image_feats = self.leakyrelu(torch.mm(self.image_embedding, self.image_trans))
            text_feats = self.leakyrelu(torch.mm(self.text_embedding, self.text_trans))
        elif self.trans == 1:
            # ä½¿ç”¨çº¿æ€§å±‚è½¬æ¢å›¾åƒå’Œæ–‡æœ¬ç‰¹å¾
            image_feats = self.image_trans_l(self.image_embedding)
            text_feats = self.text_trans_l(self.text_embedding)

        # å°†ç”¨æˆ·åµŒå…¥å’Œæ ‡å‡†åŒ–åçš„å›¾åƒç‰¹å¾æ‹¼æ¥ï¼Œä½¿ç”¨å›¾åƒé‚»æ¥çŸ©é˜µè¿›è¡Œå›¾å·ç§¯
        embedsImage = torch.concat([self.uEmbeds, F.normalize(image_feats)])
        embedsImage = torch.spmm(image_adj, embedsImage)

        # å°†ç”¨æˆ·åµŒå…¥å’Œæ ‡å‡†åŒ–åçš„æ–‡æœ¬ç‰¹å¾æ‹¼æ¥ï¼Œä½¿ç”¨æ–‡æœ¬é‚»æ¥çŸ©é˜µè¿›è¡Œå›¾å·ç§¯
        embedsText = torch.concat([self.uEmbeds, F.normalize(text_feats)])
        embedsText = torch.spmm(text_adj, embedsText)

        # å¯¹å›¾åƒç‰¹å¾è¿›è¡Œå¤šå±‚å›¾å·ç§¯å¤„ç†
        embeds1 = embedsImage
        embedsLst1 = [embeds1]
        for gcn in self.gcnLayers:  # éå† GCN å±‚ï¼Œè¿›è¡Œå›¾å·ç§¯
            embeds1 = gcn(self.adj, embedsLst1[-1])
            embedsLst1.append(embeds1)
        embeds1 = sum(embedsLst1)  # å°†æ¯ä¸€å±‚çš„å›¾å·ç§¯ç»“æœç›¸åŠ ï¼Œå½¢æˆæœ€ç»ˆçš„å›¾åƒåµŒå…¥

        # å¯¹æ–‡æœ¬ç‰¹å¾è¿›è¡Œå¤šå±‚å›¾å·ç§¯å¤„ç†
        embeds2 = embedsText
        embedsLst2 = [embeds2]
        for gcn in self.gcnLayers:  # éå† GCN å±‚ï¼Œè¿›è¡Œå›¾å·ç§¯
            embeds2 = gcn(self.adj, embedsLst2[-1])
            embedsLst2.append(embeds2)
        embeds2 = sum(embedsLst2)  # å°†æ¯ä¸€å±‚çš„å›¾å·ç§¯ç»“æœç›¸åŠ ï¼Œå½¢æˆæœ€ç»ˆçš„æ–‡æœ¬åµŒå…¥

        return embeds1[:self.num_user], embeds1[self.num_user:], embeds2[:self.num_user], embeds2[self.num_user:]

    def bpr_loss(self, users, pos_items, neg_items, user_emb, item_emb):
        # è·å–ç”¨æˆ·ã€æ­£å‘å’Œè´Ÿå‘é¡¹ç›®çš„åµŒå…¥
        user_embeddings = user_emb[users]
        pos_item_embeddings = item_emb[pos_items]
        neg_item_embeddings = item_emb[neg_items]

        # è®¡ç®—æ­£å‘å’Œè´Ÿå‘é¡¹ç›®çš„åˆ†æ•°
        pos_scores = torch.sum(user_embeddings * pos_item_embeddings, dim=1)
        neg_scores = torch.sum(user_embeddings * neg_item_embeddings, dim=1)

        # è®¡ç®— BPR æŸå¤±
        loss = -torch.mean(torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-5))

        return loss

    def regularization_loss(self, users, pos_items, neg_items, u_g, i_g):
        # è®¡ç®—æ­£åˆ™åŒ–æŸå¤±
        user_embeddings = u_g[users]
        pos_item_embeddings = i_g[pos_items]
        neg_item_embeddings = i_g[neg_items]
        reg_loss = self.reg_weight * (torch.mean(user_embeddings ** 2) + torch.mean(pos_item_embeddings ** 2)
                                      + torch.mean(neg_item_embeddings ** 2))

        return reg_loss

    def loss(self, users, pos_items, neg_items, image_adj, text_adj):
        pos_items = pos_items - self.num_user
        neg_items = neg_items - self.num_user
        users, pos_items, neg_items = users.to(self.device), pos_items.to(self.device), neg_items.to(self.device)

        usrEmbeds, itmEmbeds = self.forward_MM(image_adj, text_adj)
        self.restore_usrEmbeds = usrEmbeds
        self.restore_itmEmbeds = itmEmbeds
        bpr_loss = self.bpr_loss(users, pos_items, neg_items, usrEmbeds, itmEmbeds)
        reg_loss = self.regularization_loss(users, pos_items, neg_items, usrEmbeds, itmEmbeds)

        usrEmbeds1, itmEmbeds1, usrEmbeds2, itmEmbeds2 = self.forward_cl_MM(image_adj, text_adj)

        clLoss = (self.contrastLoss(usrEmbeds1, usrEmbeds2, users, self.ssl_temp) +
                  self.contrastLoss(itmEmbeds1, itmEmbeds2, pos_items, self.ssl_temp)) * self.ssl_alpha

        clLoss1 = (self.contrastLoss(usrEmbeds, usrEmbeds1, users, self.ssl_temp) + self.contrastLoss(itmEmbeds, itmEmbeds1, pos_items,
                                                                                       self.ssl_temp)) * self.ssl_alpha
        clLoss2 = (self.contrastLoss(usrEmbeds, usrEmbeds2, users, self.ssl_temp) + self.contrastLoss(itmEmbeds, itmEmbeds2, pos_items,
                                                                                       self.ssl_temp)) * self.ssl_alpha
        clLoss_ = clLoss1 + clLoss2

        if self.cl_method == 1:
            clLoss = clLoss_

        loss = bpr_loss + reg_loss + clLoss

        return loss

    def contrastLoss(self,embeds1, embeds2, nodes, temp):
        embeds1 = F.normalize(embeds1, p=2)
        embeds2 = F.normalize(embeds2, p=2)
        pckEmbeds1 = embeds1[nodes]
        pckEmbeds2 = embeds2[nodes]
        nume = torch.exp(torch.sum(pckEmbeds1 * pckEmbeds2, dim=-1) / temp)
        deno = torch.exp(pckEmbeds1 @ embeds2.T / temp).sum(-1)
        return -torch.log(nume / deno).mean()

    def gene_ranklist(self, topk=50):
        # stepéœ€è¦å°äºç”¨æˆ·æ•°é‡æ‰èƒ½è¾¾åˆ°åˆ†æ‰¹çš„æ•ˆæœä¸ç„¶ä¼šæŠ¥é”™
        # ç”¨æˆ·åµŒå…¥å’Œé¡¹ç›®åµŒå…¥
        user_tensor = self.restore_usrEmbeds[:self.num_user].cpu()
        item_tensor = self.restore_itmEmbeds[:self.num_item].cpu()

        # ä¸åŒé˜¶æ®µçš„è¯„ä¼°ï¼ˆä¾‹å¦‚è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•ï¼‰
        all_index_of_rank_list = torch.LongTensor([])

        # ç”Ÿæˆè¯„åˆ†çŸ©é˜µ
        score_matrix = torch.matmul(user_tensor, item_tensor.t())

        # å°†å†å²äº¤äº’è®¾ç½®ä¸ºæå°å€¼
        for row, col in self.user_item_dict.items():
            col = torch.LongTensor(list(col)) - self.num_user
            score_matrix[row][col] = 1e-6

        # é€‰å‡ºæ¯ä¸ªç”¨æˆ·çš„ top-k ä¸ªç‰©å“
        _, index_of_rank_list_train = torch.topk(score_matrix, topk)
        # æ€»çš„top-kåˆ—è¡¨
        all_index_of_rank_list = torch.cat(
            (all_index_of_rank_list, index_of_rank_list_train.cpu() + self.num_user),
            dim=0)

        # è¿”å›ä¸‰ä¸ªæ¨èåˆ—è¡¨
        return all_index_of_rank_list


class Denoise(nn.Module):
    def __init__(self, in_dims, out_dims, emb_size, norm=False, dropout=0.5):
        super(Denoise, self).__init__()
        # è¾“å…¥å’Œè¾“å‡ºç»´åº¦çš„åˆ—è¡¨ï¼Œä»¥åŠæ—¶é—´åµŒå…¥ç»´åº¦
        self.in_dims = in_dims  # [num_item, 1000]
        self.out_dims = out_dims  # [1000, num_item]
        self.time_emb_dim = emb_size  # 64
        self.norm = norm

        # å®šä¹‰æ—¶é—´åµŒå…¥çš„çº¿æ€§å±‚
        self.emb_layer = nn.Linear(self.time_emb_dim, self.time_emb_dim)

        # è¾“å…¥å±‚çš„ç»´åº¦ï¼šå°†æ—¶é—´åµŒå…¥ä¸åŸå§‹è¾“å…¥æ•°æ®çš„ç¬¬ä¸€ä¸ªç»´åº¦ï¼ˆå¦‚ç‰¹å¾ç»´åº¦ï¼‰ç›¸åŠ   [num_item + 64, 1000]
        in_dims_temp = [self.in_dims[0] + self.time_emb_dim] + self.in_dims[1:]

        out_dims_temp = self.out_dims  # [1000, num_item] è¾“å‡ºå±‚é‡æ–°å˜å›åŸæ¥çš„ç»´åº¦
        # å®šä¹‰è¾“å…¥å±‚çš„å¤šå±‚çº¿æ€§å˜æ¢ï¼ˆä½¿ç”¨ ModuleList ä¿å­˜å¤šå±‚çš„ nn.Linearï¼‰
        # num_item + 64 >> 1000
        self.in_layers = nn.ModuleList(
            [nn.Linear(d_in, d_out) for d_in, d_out in zip(in_dims_temp[:-1], in_dims_temp[1:])])
        # 1000 >> num_item
        self.out_layers = nn.ModuleList(
            [nn.Linear(d_in, d_out) for d_in, d_out in zip(out_dims_temp[:-1], out_dims_temp[1:])])

        self.drop = nn.Dropout(dropout)
        self.init_weights()

    def init_weights(self):
        for layer in self.in_layers:
            size = layer.weight.size()
            std = np.sqrt(2.0 / (size[0] + size[1]))  # Xavier åˆå§‹åŒ–
            layer.weight.data.normal_(0.0, std)  # ä½¿ç”¨æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–æƒé‡
            layer.bias.data.normal_(0.0, 0.001)  # åç½®åˆå§‹åŒ–ä¸ºä¸€ä¸ªè¾ƒå°çš„éšæœºå€¼

        for layer in self.out_layers:
            size = layer.weight.size()
            std = np.sqrt(2.0 / (size[0] + size[1]))
            layer.weight.data.normal_(0.0, std)
            layer.bias.data.normal_(0.0, 0.001)

        # åˆå§‹åŒ–æ—¶é—´åµŒå…¥å±‚çš„æƒé‡
        size = self.emb_layer.weight.size()
        std = np.sqrt(2.0 / (size[0] + size[1]))
        self.emb_layer.weight.data.normal_(0.0, std)
        self.emb_layer.bias.data.normal_(0.0, 0.001)

    def forward(self, x, timesteps, mess_dropout=True):
        # è®¡ç®—æ—¶é—´åµŒå…¥ï¼Œä½¿ç”¨æ­£å¼¦å’Œä½™å¼¦ä½ç½®ç¼–ç 
        # torch.arange ç”Ÿæˆä¸€ä¸ªä» 0 åˆ° time_emb_dim // 2 çš„å¼ é‡ç”¨äºæ—¶é—´ç¼–ç 
        freqs = torch.exp(-math.log(10000) * torch.arange(start=0, end=self.time_emb_dim // 2, dtype=torch.float32) / (
                    self.time_emb_dim // 2)).cuda()

        # å°† timesteps æ‰©å±•åˆ°ç›¸åº”çš„ç»´åº¦ï¼Œå¹¶ä¸ freqs ç›¸ä¹˜ä»¥å¾—åˆ°æ—¶é—´åµŒå…¥
        temp = timesteps[:, None].float() * freqs[None]

        # ä½¿ç”¨ cos å’Œ sin å‡½æ•°æ„é€ æ—¶é—´åµŒå…¥
        time_emb = torch.cat([torch.cos(temp), torch.sin(temp)], dim=-1)

        # å¦‚æœæ—¶é—´åµŒå…¥ç»´åº¦æ˜¯å¥‡æ•°ï¼Œè¡¥é½ä¸ºå¶æ•°ç»´åº¦
        if self.time_emb_dim % 2:
            time_emb = torch.cat([time_emb, torch.zeros_like(time_emb[:, :1])], dim=-1)

        # å°†æ—¶é—´åµŒå…¥é€šè¿‡çº¿æ€§å±‚è¿›è¡Œå¤„ç†  [batchsize, 64]
        emb = self.emb_layer(time_emb)

        if self.norm:
            x = F.normalize(x)
        if mess_dropout:
            x = self.drop(x)

        # å°†è¾“å…¥ x å’Œæ—¶é—´åµŒå…¥ emb è¿›è¡Œæ‹¼æ¥ï¼Œä½œä¸ºè¾“å…¥å±‚çš„è¾“å…¥  [batchsize, num_item + 64]
        h = torch.cat([x, emb], dim=-1)
        # ä¾æ¬¡é€šè¿‡æ¯ä¸€å±‚è¾“å…¥å±‚çš„çº¿æ€§å˜æ¢ï¼Œå¹¶ä½¿ç”¨ tanh æ¿€æ´»å‡½æ•°
        for i, layer in enumerate(self.in_layers):
            h = layer(h)
            h = torch.tanh(h)
        # ä¾æ¬¡é€šè¿‡æ¯ä¸€å±‚è¾“å‡ºå±‚çš„çº¿æ€§å˜æ¢ï¼Œé™¤äº†æœ€åä¸€å±‚ä¸ä½¿ç”¨æ¿€æ´»å‡½æ•°
        for i, layer in enumerate(self.out_layers):
            h = layer(h)
            if i != len(self.out_layers) - 1:
                h = torch.tanh(h)  # [batchsize, num_item]

        return h


class GaussianDiffusion(nn.Module):
    def __init__(self, noise_scale, noise_min, noise_max, steps, beta_fixed=True):
        super(GaussianDiffusion, self).__init__()

        # æ‰©æ•£è¿‡ç¨‹ä¸­çš„å™ªå£°ç›¸å…³å‚æ•°
        self.noise_scale = noise_scale
        self.noise_min = noise_min
        self.noise_max = noise_max
        self.steps = steps  # æ‰©æ•£çš„æ­¥æ•°

        # å¦‚æœå™ªå£°æ¯”ä¾‹ä¸ä¸º0ï¼Œè®¡ç®—æ¯ä¸€æ­¥çš„å™ªå£°ç³»æ•° beta
        if noise_scale != 0:
            self.betas = torch.tensor(self.get_betas(), dtype=torch.float64).cuda()
            if beta_fixed:
                self.betas[0] = 0.0001

            self.calculate_for_diffusion()

    # è®¡ç®—æ‰©æ•£è¿‡ç¨‹ä¸­çš„ beta ç³»æ•°ï¼Œç”¨äºåœ¨æ¯ä¸€æ­¥æ·»åŠ å™ªå£°
    def get_betas(self):
        start = self.noise_scale * self.noise_min  # å™ªå£°çš„èµ·å§‹å€¼
        end = self.noise_scale * self.noise_max  # å™ªå£°çš„ç»“æŸå€¼
        # åœ¨æ‰©æ•£æ­¥æ•°èŒƒå›´å†…çº¿æ€§æ’å€¼ï¼Œå¾—åˆ°æ¯ä¸€æ­¥çš„æ–¹å·®
        variance = np.linspace(start, end, self.steps, dtype=np.float64)
        alpha_bar = 1 - variance  # è®¡ç®— alpha_barï¼Œç”¨äºè¡¨ç¤ºå»å™ªè¿‡ç¨‹ä¸­çš„ä¿æŒç‡
        betas = []
        betas.append(1 - alpha_bar[0])  # åˆå§‹ beta å€¼
        # é€æ­¥è®¡ç®—æ¯ä¸€æ­¥çš„ beta å€¼
        for i in range(1, self.steps):
            betas.append(min(1 - alpha_bar[i] / alpha_bar[i - 1], 0.999))
        return np.array(betas)  # è¿”å› beta çš„æ•°ç»„

    # è®¡ç®—æ‰©æ•£å’Œå»å™ªè¿‡ç¨‹ä¸­éœ€è¦çš„å‚æ•°
    def calculate_for_diffusion(self):
        alphas = 1.0 - self.betas  # alpha ç”¨äºè¡¨ç¤ºæ¯ä¸€æ­¥ä¸­å»å™ªåä¿ç•™çš„æ•°æ®æ¯”ä¾‹
        # è®¡ç®— alpha çš„ç´¯ç§¯ä¹˜ç§¯ï¼Œå³ alpha çš„é€æ­¥ç§¯ç´¯è¿‡ç¨‹
        self.alphas_cumprod = torch.cumprod(alphas, dim=0).cuda()
        # å‰ä¸€æ­¥çš„ alpha ç´¯ç§¯ä¹˜ç§¯ï¼Œåˆå§‹æ—¶å‡è®¾ä¸º 1
        self.alphas_cumprod_prev = torch.cat([torch.tensor([1.0]).cuda(), self.alphas_cumprod[:-1]]).cuda()
        # ä¸‹ä¸€æ­¥çš„ alpha ç´¯ç§¯ä¹˜ç§¯ï¼Œæœ€åä¸€æ­¥å‡è®¾ä¸º 0
        self.alphas_cumprod_next = torch.cat([self.alphas_cumprod[1:], torch.tensor([0.0]).cuda()]).cuda()

        # è®¡ç®— alpha ç´¯ç§¯ä¹˜ç§¯çš„å¹³æ–¹æ ¹ï¼Œç”¨äºå»å™ªè¿‡ç¨‹ä¸­ä¿ç•™çš„æ¯”ä¾‹
        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)
        # è®¡ç®— 1 - alpha ç´¯ç§¯ä¹˜ç§¯çš„å¹³æ–¹æ ¹ï¼Œç”¨äºå»å™ªè¿‡ç¨‹ä¸­å™ªå£°çš„æ¯”ä¾‹
        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alphas_cumprod)
        # è®¡ç®— log(1 - alpha ç´¯ç§¯ä¹˜ç§¯)
        self.log_one_minus_alphas_cumprod = torch.log(1.0 - self.alphas_cumprod)
        # è®¡ç®— alpha ç´¯ç§¯ä¹˜ç§¯çš„å€’æ•°å¹³æ–¹æ ¹
        self.sqrt_recip_alphas_cumprod = torch.sqrt(1.0 / self.alphas_cumprod)
        # è®¡ç®— 1/alpha ç´¯ç§¯ä¹˜ç§¯ - 1 çš„å¹³æ–¹æ ¹ï¼Œç”¨äºåç»­é‡‡æ ·çš„æ–¹å·®è°ƒæ•´
        self.sqrt_recipm1_alphas_cumprod = torch.sqrt(1.0 / self.alphas_cumprod - 1)

        # è®¡ç®—åéªŒåˆ†å¸ƒçš„æ–¹å·®ï¼Œå…¬å¼æ¥æºäºæ‰©æ•£æ¨¡å‹ä¸­åéªŒçš„æ¨å¯¼ï¼š
        # betas * (1 - å‰ä¸€æ­¥ alpha ç´¯ç§¯ä¹˜ç§¯) / (1 - å½“å‰æ­¥çš„ alpha ç´¯ç§¯ä¹˜ç§¯)
        #  eq8ä¸­çš„æ–¹å·®
        self.posterior_variance = (
                self.betas * (1.0 - self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod)
        )
        # è®¡ç®—åéªŒæ–¹å·®çš„å¯¹æ•°ï¼Œå¹¶å°†ç¬¬ä¸€ä¸ªå…ƒç´ å›ºå®šä¸ºåç»­è®¡ç®—æ–¹ä¾¿
        self.posterior_log_variance_clipped = torch.log(
            torch.cat([self.posterior_variance[1].unsqueeze(0), self.posterior_variance[1:]]))

        # è®¡ç®—åéªŒå‡å€¼çš„ä¸¤ä¸ªç³»æ•°ï¼Œåˆ†åˆ«ç”¨äºè¡¨ç¤ºåœ¨å»å™ªè¿‡ç¨‹ä¸­å‡å€¼çš„çº¿æ€§ç»„åˆ
        # ç³»æ•° 1ï¼šbetas * sqrt(å‰ä¸€æ­¥ alpha ç´¯ç§¯ä¹˜ç§¯) / (1 - å½“å‰æ­¥ alpha ç´¯ç§¯ä¹˜ç§¯)  eq8å’Œeq10ä¸­åé¢ä¸€é¡¹çš„ç³»æ•°
        self.posterior_mean_coef1 = (self.betas * torch.sqrt(self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod))
        # ç³»æ•° 2ï¼š(1 - å‰ä¸€æ­¥ alpha ç´¯ç§¯ä¹˜ç§¯) * sqrt(alpha) / (1 - å½“å‰æ­¥ alpha ç´¯ç§¯ä¹˜ç§¯)  eq8å’Œeq10ä¸­å‰é¢ä¸€é¡¹çš„ç³»æ•°
        self.posterior_mean_coef2 = (
                    (1.0 - self.alphas_cumprod_prev) * torch.sqrt(alphas) / (1.0 - self.alphas_cumprod))

    # ä»ç»™å®šçš„åˆå§‹çŠ¶æ€ x_start ä¸­é€æ­¥é‡‡æ ·ï¼Œæ¢å¤å‡ºåŸå§‹æ•°æ®
    def p_sample(self, model, x_start, steps, sampling_noise=False):
        # å¦‚æœæ­¥æ•°æ˜¯ 0ï¼Œç›´æ¥ä½¿ç”¨åˆå§‹ç”¨æˆ·-é¡¹ç›®äº¤äº’åºåˆ—
        if steps == 0:
            x_t = x_start
        else:
            # æ„é€ ä¸€ä¸ªé•¿åº¦ä¸º x_start çš„ t å¼ é‡ï¼Œå€¼ä¸º steps - 1ï¼Œç”¨äºä»æ‰©æ•£è¿‡ç¨‹ä¸­æå–æ ·æœ¬
            t = torch.tensor([steps - 1] * x_start.shape[0]).cuda()
            # è°ƒç”¨ q_sample å‡½æ•°ï¼Œç”Ÿæˆå¸¦å™ªå£°çš„ x_t
            x_t = self.q_sample(x_start, t)

        # åˆ›å»ºä¸€ä¸ªç´¢å¼•åˆ—è¡¨ï¼Œè¡¨ç¤ºåå‘é‡‡æ ·æ­¥éª¤çš„é¡ºåºï¼Œä» steps-1 åˆ° 0
        indices = list(range(self.steps))[::-1]

        # é€æ­¥æ‰§è¡Œä» t = steps-1 åˆ° t = 0 çš„é‡‡æ ·è¿‡ç¨‹
        for i in indices:
            # ä¸ºæ¯ä¸€ä¸ªæ­¥æ•°åˆ›å»ºä¸€ä¸ª t å¼ é‡
            t = torch.tensor([i] * x_t.shape[0]).cuda()
            # é€šè¿‡æ¨¡å‹è®¡ç®—åéªŒå‡å€¼å’Œå¯¹æ•°æ–¹å·®
            model_mean, model_log_variance = self.p_mean_variance(model, x_t, t)

            # å¦‚æœå¼€å¯äº†é‡‡æ ·å™ªå£°ï¼Œåˆ™åŠ å…¥å™ªå£°
            if sampling_noise:
                # ç”Ÿæˆä¸ x_t å½¢çŠ¶ç›¸åŒçš„æ ‡å‡†æ­£æ€å™ªå£°
                noise = torch.randn_like(x_t)
                # ç¡®ä¿åœ¨æ—¶é—´æ­¥t=0æ—¶ä¸ä¼šåŠ å™ªå£°
                nonzero_mask = ((t != 0).float().view(-1, *([1] * (len(x_t.shape) - 1))))
                # æ›´æ–° x_tï¼ŒåŸºäºæ¨¡å‹çš„å‡å€¼å’Œå™ªå£°
                x_t = model_mean + nonzero_mask * torch.exp(0.5 * model_log_variance) * noise
            else:
                x_t = model_mean  # å¦‚æœä¸åŠ å™ªå£°ï¼Œç›´æ¥ä½¿ç”¨å‡å€¼ä½œä¸ºä¸‹ä¸€æ­¥çš„at-1
        return x_t

    # æ‰§è¡Œæ‰©æ•£æ¨¡å‹ä¸­çš„å‰å‘è¿‡ç¨‹ï¼Œå®ƒåœ¨æ¯ä¸€æ­¥ä¸­å‘æ•°æ®ä¸­åŠ å…¥å™ªå£° eq2
    def q_sample(self, x_start, t, noise=None):
        # x_startä»£è¡¨è®ºæ–‡ä¸­çš„a0ï¼Œè¡¨ç¤ºåŸå§‹ç”¨æˆ·é¡¹ç›®äº¤äº’åºåˆ—
        if noise is None:
            noise = torch.randn_like(x_start)

        # æå– alpha çš„å¹³æ–¹æ ¹å¹¶å¯¹ x_start åŠ æƒ
        alpha_t = self._extract_into_tensor(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start

        # æå– (1 - alpha) çš„å¹³æ–¹æ ¹å¹¶å¯¹å™ªå£°åŠ æƒ
        one_minus_alpha_t = self._extract_into_tensor(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise

        # è¿”å›åŠ æƒåçš„ç»“æœ
        return alpha_t + one_minus_alpha_t

    # ä»ç»™å®šçš„æ•°ç»„ arr ä¸­æå–ä¸æ—¶é—´æ­¥ t å¯¹åº”çš„å€¼ï¼Œå¹¶æ‰©å±•ç»´åº¦ä»¥é€‚åº” broadcast_shape
    def _extract_into_tensor(self, arr, timesteps, broadcast_shape):
        arr = arr.cuda()
        # æ ¹æ®æ—¶é—´æ­¥ t æå–æ•°ç»„ä¸­å¯¹åº”çš„å€¼ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºæµ®ç‚¹æ•°
        res = arr[timesteps].float()
        while len(res.shape) < len(broadcast_shape):
            res = res[..., None]
        return res.expand(broadcast_shape)

    # æ ¹æ®æ¨¡å‹è¾“å‡ºå’Œæ‰©æ•£è¿‡ç¨‹ä¸­çš„æ—¶é—´æ­¥ tï¼Œè®¡ç®—æ¨¡å‹çš„å‡å€¼å’Œæ–¹å·®  eq4çš„å‡å€¼å’Œæ–¹å·®
    def p_mean_variance(self, model, x, t):
        # ä½¿ç”¨æ¨¡å‹è¾“å‡ºï¼Œå‡è®¾æ¨¡å‹æ ¹æ®è¾“å…¥ x(at) å’Œæ—¶é—´æ­¥ t è¿”å›ç»“æœ
        model_output = model(x, t, False)  # ç›¸å½“äºé¢„æµ‹åˆå§‹çŠ¶æ€a0
        # åéªŒåˆ†å¸ƒçš„æ–¹å·®å’Œå¯¹æ•°æ–¹å·®ï¼Œå·²ç»é¢„å…ˆè®¡ç®—å¥½
        # model_variance = self.posterior_variance
        model_log_variance = self.posterior_log_variance_clipped

        # æ ¹æ®æ—¶é—´æ­¥ t ä»æ–¹å·®å’Œå¯¹æ•°æ–¹å·®ä¸­æå–å¯¹åº”çš„å€¼ï¼Œå¹¶æ‰©å±•åˆ°è¾“å…¥ x çš„å½¢çŠ¶
        # model_variance = self._extract_into_tensor(model_variance, t, x.shape)
        model_log_variance = self._extract_into_tensor(model_log_variance, t, x.shape)

        # è®¡ç®—åéªŒå‡å€¼ã€‚é€šè¿‡ posterior_mean_coef1 å’Œ posterior_mean_coef2 åŠ æƒæ¨¡å‹è¾“å‡ºå’Œè¾“å…¥ x
        model_mean = (self._extract_into_tensor(self.posterior_mean_coef1, t,
                                                x.shape) * model_output + self._extract_into_tensor(
            self.posterior_mean_coef2, t, x.shape) * x)

        # è¿”å›æ¨¡å‹å‡å€¼å’Œå¯¹æ•°æ–¹å·®
        return model_mean, model_log_variance

    # ELBO æŸå¤±
    def training_losses(self, model, x_start, itmEmbeds, batch_index, model_feats):
        batch_size = x_start.size(0)
        # éšæœºé€‰æ‹©æ—¶é—´æ­¥ tsï¼ŒèŒƒå›´ä¸º 0 åˆ° self.steps
        ts = torch.randint(0, self.steps, (batch_size,)).long().cuda()
        # ç”Ÿæˆä¸ x_start å½¢çŠ¶ç›¸åŒçš„éšæœºå™ªå£°
        noise = torch.randn_like(x_start)
        # å¦‚æœå™ªå£°æ¯”ä¾‹ä¸ä¸º 0ï¼Œæ‰§è¡Œå‰å‘æ‰©æ•£è¿‡ç¨‹ç”Ÿæˆ x_t
        if self.noise_scale != 0:
            x_t = self.q_sample(x_start, ts, noise)  # ç”Ÿæˆå¸¦å™ªå£°çš„ç”¨æˆ·é¡¹ç›®äº¤äº’åºåˆ—
        else:
            x_t = x_start

        # é€šè¿‡æ¨¡å‹ç”Ÿæˆé¢„æµ‹è¾“å‡º(å»å™ªè¿‡ç¨‹p)
        model_output = model(x_t, ts)

        # è®¡ç®—å‡æ–¹è¯¯å·® MSEï¼ŒL0éƒ¨åˆ†(eq12)
        mse = self.mean_flat((x_start - model_output) ** 2)

        # è®¡ç®— ts-1 å’Œ ts ä¹‹é—´çš„ SNR å·®å¼‚ï¼Œç”¨äºæƒé‡è°ƒèŠ‚
        # weight è®¡ç®—äº†æ—¶é—´æ­¥ $t$ ä¸Šçš„ SNR å·®å¼‚ï¼Œè¿™åæ˜ äº†ä¸åŒæ—¶é—´æ­¥ KL æ•£åº¦çš„åŠ æƒ
        weight = self.SNR(ts - 1) - self.SNR(ts)
        # å¦‚æœæ—¶é—´æ­¥ ts ä¸º 0ï¼Œåˆ™å°†æƒé‡è®¾ç½®ä¸º 1.0ï¼ˆå³ä¸è¡°å‡ï¼‰
        weight = torch.where((ts == 0), 1.0, weight)

        # diff_loss æ˜¯åŠ æƒåçš„ ELBO æŸå¤±
        diff_loss = weight * mse

        # ==============æ¨¡æ€æ„ŸçŸ¥ä¿¡å·æ³¨å…¥===================
        # è®¡ç®—ç”¨æˆ·æ¨¡å‹åµŒå…¥ä¸æ¨¡å‹ç‰¹å¾ä¹‹é—´çš„ç‚¹ç§¯
        usr_model_embeds = torch.mm(model_output, model_feats)
        # è®¡ç®—ç”¨æˆ· ID åµŒå…¥ä¸ç‰©å“åµŒå…¥ä¹‹é—´çš„ç‚¹ç§¯
        usr_id_embeds = torch.mm(x_start, itmEmbeds)

        # gc_lossï¼Œè¡¡é‡ç”¨æˆ·æ¨¡å‹åµŒå…¥å’Œç”¨æˆ· ID åµŒå…¥ä¹‹é—´çš„å·®å¼‚(eq14ä¸­çš„msiæŸå¤±)
        gc_loss = self.mean_flat((usr_model_embeds - usr_id_embeds) ** 2)

        return diff_loss, gc_loss

    def mean_flat(self, tensor):
        # è®¡ç®—å¼ é‡ tensor é™¤äº†ç¬¬ä¸€ç»´åº¦å¤–çš„å‡å€¼
        return tensor.mean(dim=list(range(1, len(tensor.shape))))

    # è®¡ç®—æ‰©æ•£è¿‡ç¨‹ä¸­çš„ä¿¡å™ªæ¯”
    def SNR(self, t):
        self.alphas_cumprod = self.alphas_cumprod.cuda()
        # SNR = alpha_t / (1 - alpha_t)
        return self.alphas_cumprod[t] / (1 - self.alphas_cumprod[t])