Mon 11 Mar 2024 20:28:57 INFO ============Arguments==============
Mon 11 Mar 2024 20:28:57 INFO Model: DMRL
Mon 11 Mar 2024 20:28:57 INFO data_path: beauty
Mon 11 Mar 2024 20:28:57 INFO learning_rate: 0.001
Mon 11 Mar 2024 20:28:57 INFO feature_embed: 64
Mon 11 Mar 2024 20:28:57 INFO batch_size: 1024
Mon 11 Mar 2024 20:28:57 INFO aggr_mode: add
Mon 11 Mar 2024 20:28:57 INFO reg_weight: 0.001
Mon 11 Mar 2024 20:28:57 INFO dim_E: 64
Mon 11 Mar 2024 20:28:57 INFO num_epoch: 1000
Mon 11 Mar 2024 20:28:57 INFO dropout: 0.2
Mon 11 Mar 2024 20:28:57 INFO n_layers: 2
Mon 11 Mar 2024 20:28:57 INFO corDecay: 0.001
Mon 11 Mar 2024 20:28:57 INFO n_factors: 4
Mon 11 Mar 2024 20:28:57 INFO n_iterations: 3
Mon 11 Mar 2024 20:28:57 INFO cl_weight: 2.0
Mon 11 Mar 2024 20:28:57 INFO mm_layers: 2
Mon 11 Mar 2024 20:28:57 INFO ii_topk: 10
Mon 11 Mar 2024 20:28:57 INFO uu_topk: 40
Mon 11 Mar 2024 20:28:57 INFO lambda_coeff: 0.9
Mon 11 Mar 2024 20:28:57 INFO ssl_temp: 0.9
Mon 11 Mar 2024 20:28:57 INFO ssl_alpha: 0.9
Mon 11 Mar 2024 20:28:57 INFO ae_weight: 0.1
Mon 11 Mar 2024 20:28:57 INFO threshold: 0.1
Mon 11 Mar 2024 20:28:57 INFO prompt_num: 0.1
Mon 11 Mar 2024 20:28:57 INFO neg_weight: 0.1
Mon 11 Mar 2024 20:28:57 INFO seed: 42
Mon 11 Mar 2024 20:28:57 INFO num_workers: 1
Mon 11 Mar 2024 20:28:57 INFO topk: [5, 10, 20]
Mon 11 Mar 2024 20:28:57 INFO local time£ºMar-11-2024-20-28-57
Mon 11 Mar 2024 20:28:57 INFO =========1/1: Parameters:{'learning_rate': 0.1, 'reg_weight': 0.001, 'corDecay': 1, 'n_factors': 4}=========
Mon 11 Mar 2024 20:29:07 INFO Epoch 1, Loss: 239.01357
